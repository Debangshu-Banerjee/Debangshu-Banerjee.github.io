<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Debangshu  Banerjee</title>
    <meta name="author" content="Debangshu  Banerjee" />
    <meta name="description" content="Profile website of Debangshu Banerjee.
" />
    <meta name="keywords" content="academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/">
    
    <!-- Dark Mode -->
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/Resume/">Resume</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title">
           <b><span class="special">Debangshu</span></b> 
           Banerjee
          </h1>
          
          <p class="desc">CS PhD Student @ <a href="https://cs.illinois.edu/" target="_blank" rel="noopener noreferrer">UIUC</a></p>
        </header>

        <article>
          <div class="profile float-right">

              <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img class="img-fluid z-dept-1 rounded-circle" src="/assets/img/debangshu_pic.jpg" width="auto" height="auto" alt="debangshu_pic.jpg">

  </picture>

</figure>
<div>
    <table align="center">
        <tbody>
            <tr>
                <td align="center"><a href="mailto:db21@illinois.edu">E-mail</a></td>
                <td align="center">~</td>
                <td align="center"><a href="https://github.com/Debangshu-Banerjee" target="_blank" rel="noopener noreferrer">Github</a></td>
                <td align="center">~</td>
                <td align="center"><a href="https://www.linkedin.com/in/debangshu-banerjee" target="_blank" rel="noopener noreferrer">LinkedIn</a></td>
                <td align="center">~</td>
                <td align="center"><a href="https://twitter.com/debangshuban18" target="_blank" rel="noopener noreferrer">Twitter</a></td>
                <!-- <td align="center">|</a></td> -->
            </tr>
        </tbody>
    </table>
</div>

            </div>

          <div class="clearfix">
            <p>I am a 2nd year PhD student in the Computer Science department at the <a href="https://cs.illinois.edu/" target="_blank" rel="noopener noreferrer">University of Illinois, Urbana-Champaign</a>. I am interested in Formal Reasoning about large scale differentiable programs. I am presently advised by <a href="https://ggndpsngh.github.io/" target="_blank" rel="noopener noreferrer">Prof. Gagandeep Singh</a>.</p>

<p>I am currently looking into different problems related to Deep Neural Network (DNN) verification including - verification of relational properties, incremental verification and formal guarantees for DNN intepretation techniques.</p>

          </div>



          <!-- Selected papers -->
          <div class="publications">
            <h2>Selected Publications</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">RABBit</abbr></div>

        <!-- Entry bib key -->
        <div id="rabbit" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Precise Relational DNN Verification With Cross Executional Branching</div>
          <!-- Author -->
          <div class="author">Suresh, Tarun, 
                  <em>Banerjee, Debangshu</em>, and Singh, Gagandeep
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS)</em> 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=W5U3XB1C11" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/RABBit.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We propose RABBit, a Branch-and-Bound-based verifier for verifying relational properties defined over Deep Neural Networks, such as robustness against universal adversarial perturbations (UAP). Existing state-of-the-art (SOTA) complete 
input specific robustness verifiers can not reason about dependencies between multiple executions and, as a result, are imprecise for relational verification. In contrast, existing SOTA relational verifiers only apply a single bounding step and do not utilize any branching strategies to refine the obtained bounds, thus producing imprecise results. We develop the first scalable Branch-and-Bound-based relational verifier, RABBit, which efficiently combines branching over multiple executions with cross-executional bound refinement to utilize relational constraints, gaining substantial precision over SOTA baselines on a wide range of datasets and networks.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">RACoon</abbr></div>

        <!-- Entry bib key -->
        <div id="banerjee2024relational" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Relational DNN Verification With Cross Executional Bound Refinement</div>
          <!-- Author -->
          <div class="author">
                  <em>Banerjee, Debangshu</em>, and Singh, Gagandeep
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Forty-first International Conference on Machine Learning (ICML)</em> 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=HOG80Yk4Gw" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Racoon.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We focus on verifying relational properties defined over deep neural networks (DNNs) such as robustness against universal adversarial perturbations (UAP), certified worst-case hamming distance for binary string classifications, etc. Precise verification of these properties requires reasoning about multiple executions of the same DNN. However, most of the existing works in DNN verification only handle properties defined over single executions and as a result, are imprecise for relational properties. Though few recent works for relational DNN verification, capture linear dependencies between the inputs of multiple executions, they do not leverage dependencies between the outputs of hidden layers producing imprecise results. We develop a scalable relational verifier RACoon that utilizes cross-execution dependencies at all layers of the DNN gaining substantial precision over SOTA baselines on a wide range of datasets, networks, and relational properties.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">RaVeN</abbr></div>

        <!-- Entry bib key -->
        <div id="banerjeeRaven" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Input-Relational Verification of Deep Neural Networks</div>
          <!-- Author -->
          <div class="author">
                  <em>Banerjee, Debangshu</em>, Xu, Calvin, and Singh, Gagandeep
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Programming Language Design and Implementation (PLDI)</em> 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dl.acm.org/doi/abs/10.1145/3656377" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/RaVeN.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We consider the verification of input-relational properties defined over deep neural networks (DNNs) such as robustness against universal adversarial perturbations, monotonicity, etc. Precise verification of these properties requires reasoning about multiple executions of the same DNN. We introduce a novel concept of difference tracking to compute the difference between the outputs of two executions of the same DNN at all layers. We design a new abstract domain, DiffPoly for efficient difference tracking that can scale large DNNs. DiffPoly is equipped with custom abstract transformers for common activation functions (ReLU, Tanh, Sigmoid, etc.) and affine layers and can create precise linear cross-execution constraints. We implement an input-relational verifier for DNNs called RaVeN which uses DiffPoly and linear program formulations to handle a wide range of input-relational properties. Our experimental results on challenging benchmarks show that by leveraging precise linear constraints defined over multiple executions of the DNN, RaVeN gains substantial precision over baselines on a wide range of datasets, networks, and input-relational properties.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ProFIt</abbr></div>

        <!-- Entry bib key -->
        <div id="banerjee2024dissecting" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Interpreting Robustness Proofs of Deep Neural Networks</div>
          <!-- Author -->
          <div class="author">
                  <em>Banerjee, Debangshu</em>, Singh, Avaljot, and Singh, Gagandeep
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In The Twelfth International Conference on Learning Representations (ICLR)</em> 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=Ev10F9TWML" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Profit.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In recent years numerous methods have been developed to formally verify the robustness of deep neural networks (DNNs). Though the proposed techniques are effective in providing mathematical guarantees about the DNNs’ behavior, it is not clear whether the proofs generated by these methods are human understandable. In this paper, we bridge this gap by developing new concepts, algorithms, and representations to generate human understandable insights into the internal workings of DNN robustness proofs. Leveraging the proposed method, we show that the robustness proofs of standard DNNs rely more on spurious input features as compared to the proofs of DNNs trained to be robust. Robustness proofs of the provably robust DNNs filter out a larger number of spurious input features as compared to adversarially trained DNNs, sometimes even leading to the pruning of semantically meaningful input features. The proofs for the DNNs combining adversarial and provably robust training tend to achieve the middle ground.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IRS</abbr></div>

        <!-- Entry bib key -->
        <div id="ugare2024incremental" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Incremental Randomized Smoothing Certification</div>
          <!-- Author -->
          <div class="author">Ugare, Shubham, Suresh, Tarun, 
                  <em>Banerjee, Debangshu</em>, Singh, Gagandeep, and Misailovic, Sasa
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In The Twelfth International Conference on Learning Representations (ICLR)</em> 2024
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://openreview.net/forum?id=SdeAPV1irk" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Irs.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Randomized smoothing-based certification is an effective approach for obtaining robustness certificates of deep neural networks (DNNs) against adversarial attacks. This method constructs a smoothed DNN model and certifies its robustness through statistical sampling, but it is computationally expensive, especially when certifying with a large number of samples. Furthermore, when the smoothed model is modified (e.g., quantized or pruned), certification guarantees may not hold for the modified DNN, and recertifying from scratch can be prohibitively expensive.
We present the first approach for incremental robustness certification for randomized smoothing, IRS. We show how to reuse the certification guarantees for the original smoothed model to certify an approximated model with very few samples. IRS significantly reduces the computational cost of certifying modified DNNs while maintaining strong robustness guarantees. We experimentally demonstrate the effectiveness of our approach, showing up to 4.1x certification speedup over the certification that applies randomized smoothing of the approximate model from scratch.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IVAN</abbr></div>

        <!-- Entry bib key -->
        <div id="10.1145/3591299" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Incremental Verification of Neural Networks</div>
          <!-- Author -->
          <div class="author">Ugare, Shubham, 
                  <em>Banerjee, Debangshu</em>, Misailovic, Sasa, and Singh, Gagandeep
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>Programming Language Design and Implementation (PLDI)</em> Jun 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1145/3591299" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
            <a href="/assets/pdf/Ivan.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Complete verification of deep neural networks (DNNs) can exactly determine whether the DNN satisfies a desired trustworthy property (e.g., robustness, fairness) on an infinite set of inputs or not. Despite the tremendous progress to improve the scalability of complete verifiers over the years on individual DNNs, they are inherently inefficient when a deployed DNN is updated to improve its inference speed or accuracy. The inefficiency is because the expensive verifier needs to be run from scratch on the updated DNN. To improve efficiency, we propose a new, general framework for incremental and complete DNN verification based on the design of novel theory, data structure, and algorithms. Our contributions implemented in a tool named IVAN yield an overall geometric mean speedup of 2.4x for verifying challenging MNIST and CIFAR10 classifiers and a geometric mean speedup of 3.8x for the ACAS-XU classifiers over the state-of-the-art baselines.</p>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>
<div class="affiliations">
    <h5>Affiliations &amp; Internships</h5>

    <table align="center">
        <tbody>
        <tr>
            <td align="center">
                <a href="https://www.iitg.ac.in/" target="_blank" rel="noopener noreferrer">
                <img style="width:80px" src="/assets/img/iitg_logo.png"></a>   
            </td>
            <td align="center">
                <a href="" target="_blank">
                <img style="width:120px" src="/assets/img/google_logo.jpg"></a>   
            </td>
            <td align="center">
                <a href="" target="_blank">
                <img style="width:120px" src="/assets/img/google_logo.jpg"></a>   
            </td>
            <td align="center">
                <a href="https://cs.illinois.edu/" target="_blank" rel="noopener noreferrer">
                <img style="width:80px" src="/assets/img/uiuc_logo.png"></a>   
            </td>
        </tr>
        <tr>
            <td align="center" style="padding: 10px;"><font size="2">IIT Guwahati<br>2016-2020<br>B. Tech Computer Science</font></td>
            <td align="center" style="padding: 10px;"><font size="2">Google <br>Summer 2019<br>SDE Intern</font></td>
            <td align="center" style="padding: 10px;"><font size="2">Google <br>2020-2022<br>Software Engineer (L4) </font></td>
            <td align="center" style="padding: 10px;"><font size="2">UIUC<br>2022-Present<br>PhD Computer Science</font></td>
        </tr>
        </tbody>
    </table>
  </div>

          
        </article>

</div>

    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        © 2024 Debangshu  Banerjee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme.
Last updated: October 11, 2024.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script async src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script async src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script async src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>
